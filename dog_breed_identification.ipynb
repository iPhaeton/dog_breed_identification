{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(image_size, random_state=1):\n",
    "    labels = pd.read_csv('./data/labels.csv')\n",
    "    sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "    print('Train data size:', labels.shape[0])\n",
    "    print('Test data size:', sample_submission.shape[0])\n",
    "    labels_one_hot = np.array(pd.get_dummies(labels['breed'], sparse=True))\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    for i, id in enumerate(labels['id']):\n",
    "        image = np.array(ndimage.imread('./data/train/' + id + '.jpg', flatten=False))\n",
    "        x_train.append(scipy.misc.imresize(image, size=(image_size, image_size)))\n",
    "        y_train.append(labels_one_hot[i])\n",
    "        if (i % 1000 == 0) and (i != 0):\n",
    "            print(i, 'images processed')\n",
    "\n",
    "    for i, id in enumerate(sample_submission['id']):\n",
    "        image = np.array(ndimage.imread('./data/test/' + id + '.jpg', flatten=False))\n",
    "        x_test.append(scipy.misc.imresize(image, size=(image_size, image_size)))\n",
    "        if (i % 1000 == 0) and (i != 0):\n",
    "            print(i, 'images processed')\n",
    "                \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    \n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x_train, y_train, test_size=0.3, random_state=random_state)\n",
    "                \n",
    "    np.save('./data/raw/X_train', X_train)\n",
    "    np.save('./data/raw/Y_train', Y_train)\n",
    "    np.save('./data/raw/X_dev', X_dev)\n",
    "    np.save('./data/raw/Y_dev', Y_dev)\n",
    "    np.save('./data/raw/x_test', x_test)\n",
    "\n",
    "    print('Train dataset:', x_train.shape)\n",
    "    print('Train labels:', y_train.shape)\n",
    "    print('Test dataset:', x_test.shape)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load (name, normalize):\n",
    "    data = np.load('./data/raw/' + name + '.npy')\n",
    "    if normalize == True:\n",
    "        data = data / 255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 10222\n",
      "Test data size: 10357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n",
      "Train dataset: (10222, 90, 90, 3)\n",
      "Train labels: (10222, 120)\n",
      "Test dataset: (10357, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "#execute only once\n",
    "prepare_data(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('X_train', normalize=True)\n",
    "Y_train = load('Y_train', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (image_size, image_size, 3)\n",
    "\n",
    "X_input = Input(input_size)\n",
    "\n",
    "X = Conv2D(96, (11, 11), strides=(4,4), activation='relu')(X_input)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "X = Conv2D(256, (5,5), padding='same', activation='relu')(X)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "X = Conv2D(384, (3,3), padding='same', activation='relu')(X)\n",
    "X = Conv2D(384, (3,3), padding='same', activation='relu')(X)\n",
    "X = Conv2D(256, (3,3), padding='same', activation='relu')(X)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(1024, activation='relu')(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "output = Dense(120, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=X_input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 97s 14ms/step - loss: 4.7891 - acc: 0.0067\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 96s 13ms/step - loss: 4.7824 - acc: 0.0109\n",
      "Epoch 3/100\n",
      " 512/7155 [=>............................] - ETA: 1:22 - loss: 4.7828 - acc: 0.0059"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=512,\n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
