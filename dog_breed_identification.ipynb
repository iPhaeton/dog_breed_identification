{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(image_size, random_state=1):\n",
    "    labels = pd.read_csv('./data/labels.csv')\n",
    "    sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "    print('Train data size:', labels.shape[0])\n",
    "    print('Test data size:', sample_submission.shape[0])\n",
    "    labels_one_hot = np.array(pd.get_dummies(labels['breed'], sparse=True))\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    for i, id in enumerate(labels['id']):\n",
    "        image = np.array(ndimage.imread('./data/train/' + id + '.jpg', flatten=False))\n",
    "        x_train.append(scipy.misc.imresize(image, size=(image_size, image_size)))\n",
    "        y_train.append(labels_one_hot[i])\n",
    "        if (i % 1000 == 0) and (i != 0):\n",
    "            print(i, 'images processed')\n",
    "\n",
    "    for i, id in enumerate(sample_submission['id']):\n",
    "        image = np.array(ndimage.imread('./data/test/' + id + '.jpg', flatten=False))\n",
    "        x_test.append(scipy.misc.imresize(image, size=(image_size, image_size)))\n",
    "        if (i % 1000 == 0) and (i != 0):\n",
    "            print(i, 'images processed')\n",
    "                \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    \n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x_train, y_train, test_size=0.3, random_state=random_state)\n",
    "                \n",
    "    np.save('./data/raw/X_train', X_train)\n",
    "    np.save('./data/raw/Y_train', Y_train)\n",
    "    np.save('./data/raw/X_dev', X_dev)\n",
    "    np.save('./data/raw/Y_dev', Y_dev)\n",
    "    np.save('./data/raw/x_test', x_test)\n",
    "\n",
    "    print('Train dataset:', x_train.shape)\n",
    "    print('Train labels:', y_train.shape)\n",
    "    print('Test dataset:', x_test.shape)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load (name, normalize):\n",
    "    data = np.load('./data/raw/' + name + '.npy')\n",
    "    if normalize == True:\n",
    "        data = data / 255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 90\n",
    "input_size = (image_size, image_size, 3)\n",
    "num_class = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 10222\n",
      "Test data size: 10357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n",
      "Train dataset: (10222, 90, 90, 3)\n",
      "Train labels: (10222, 120)\n",
      "Test dataset: (10357, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "#execute only once\n",
    "prepare_data(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('X_train', normalize=True)\n",
    "Y_train = load('Y_train', normalize=False)\n",
    "\n",
    "X_dev = load('X_dev', normalize=True)\n",
    "Y_dev = load('Y_dev', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        f, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=False)\n",
    "        self.ax1 = ax1\n",
    "        self.ax2 = ax2\n",
    "    \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('categorical_accuracy'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_categorical_accuracy'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        self.ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        self.ax1.plot(self.x, self.val_losses, label=\"val loss\")\n",
    "        self.ax1.legend()\n",
    "        self.ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        self.ax2.plot(self.x, self.val_acc, label=\"val accuracy\")\n",
    "        self.ax2.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        print(logs)\n",
    "        for i in range(self.i):\n",
    "            print('Epoch ' + str(i+1))\n",
    "            print('-----------------------')\n",
    "            print('- Loss:', self.losses[i])\n",
    "            print('- Accuracy:', self.acc[i])\n",
    "            print('- Validation loss:', self.val_losses[i])\n",
    "            print('- Validation accuracy:', self.val_acc[i])\n",
    "            print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = Input(input_size)\n",
    "\n",
    "X = Conv2D(96, (11, 11), strides=(4,4), activation='relu')(X_input)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "X = Conv2D(256, (5,5), padding='same', activation='relu')(X)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "X = Conv2D(384, (3,3), padding='same', activation='relu')(X)\n",
    "X = Conv2D(384, (3,3), padding='same', activation='relu')(X)\n",
    "X = Conv2D(256, (3,3), padding='same', activation='relu')(X)\n",
    "X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(1024, activation='relu')(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "output = Dense(120, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=X_input, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 97s 14ms/step - loss: 4.7891 - acc: 0.0067\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 96s 13ms/step - loss: 4.7824 - acc: 0.0109\n",
      "Epoch 3/100\n",
      " 512/7155 [=>............................] - ETA: 1:22 - loss: 4.7828 - acc: 0.0059"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=512,\n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 16,935,864\n",
      "Trainable params: 2,221,176\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "\n",
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(1024, activation='relu')(X)\n",
    "output= Dense(num_class, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 7.7055271148681639, 'val_categorical_accuracy': 0.01, 'loss': 0.80574963331222538, 'categorical_accuracy': 0.92000000000000004}\n",
      "Epoch 1\n",
      "-----------------------\n",
      "- Loss: 5.27433778763\n",
      "- Accuracy: 0.01\n",
      "- Validation loss: 5.64845977783\n",
      "- Validation accuracy: 0.0\n",
      " \n",
      "Epoch 2\n",
      "-----------------------\n",
      "- Loss: 2.92327362061\n",
      "- Accuracy: 0.29\n",
      "- Validation loss: 6.21817325592\n",
      "- Validation accuracy: 0.01\n",
      " \n",
      "Epoch 3\n",
      "-----------------------\n",
      "- Loss: 1.7226365757\n",
      "- Accuracy: 0.75\n",
      "- Validation loss: 6.79617961884\n",
      "- Validation accuracy: 0.04\n",
      " \n",
      "Epoch 4\n",
      "-----------------------\n",
      "- Loss: 0.805749633312\n",
      "- Accuracy: 0.92\n",
      "- Validation loss: 7.70552711487\n",
      "- Validation accuracy: 0.01\n",
      " \n",
      "Epoch 5/20\n",
      " 48/100 [=============>................] - ETA: 4s - loss: 0.3518 - categorical_accuracy: 0.9792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-906478ee0902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=(X_dev[0:100], Y_dev[0:100]))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=16,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          callbacks=[plot_losses], \n",
    "          validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = load('X_dev', normalize=True)\n",
    "Y_dev = load('Y_dev', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./model')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = np.array(list(map(np.argmax, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    m = keras.metrics.sparse_categorical_accuracy(predictions, Y_dev)\n",
    "    res = sess.run(m)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_classes = prediction_classes = np.array(list(map(np.argmax, Y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_answers = np.extract(prediction_classes != real_classes, prediction_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_answers.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
